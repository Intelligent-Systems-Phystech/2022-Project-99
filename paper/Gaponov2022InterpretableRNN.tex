\documentclass[12pt]{article}
\usepackage{arxiv}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english, russian]{babel}
\usepackage{url}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{lipsum}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{doi}

\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{mathtools}

% \renewcommand{\shorttitle}{\textit{arXiv} Template}
\renewcommand{\headeright}{}
\renewcommand{\undertitle}{}
\renewcommand{\abstractname}{Аннотация}
\newcommand{\keywordsname}{Ключевые слова:}

\begin{document}
\title{Выбор интерпретируемых рекуррентных моделей глубокого обучения}
\author{\normalsize\bf{Гапонов Максим,~Бахтеев Олег,~Яковлев Константин,~Стрижов Вадим} \\
	Московский физико-технический институт \\
	\texttt{\{gaponov.me,~bakhteev,~...,~strijov\}@phystech.edu}
}
\date{}
\maketitle
\begin{abstract}
Рассматривается задача интерпретации рекуррентных нейронных сетей. Под интерпретируемостью модели понимается возможность получить простую зависимость выходных данных от входных. Интерпретируемость нейронных сетей необходима для повышения уровня доверия к предсказаниям таких моделей. Предлагается обобщить метод OpenBox, предназначенный для интерпретации нейронных сетей с кусочно-линейными функциями активации. Нейронная сеть представляется в виде набора интерпретируемых линейных классификаторов. Каждый из классификаторов определён на выпуклом многограннике. Поэтому интерпретации близких объектов оказываются согласованными. Для проверки работоспособности предложенного метода проводится эксперимент на выборке IMDB Review dataset.
\end{abstract}

\keywords{Интерпретация моделей \and Рекуррентные нейронные сети \and Кусочно-линейные модели}

\section{Введение}
В работе рассматривается метод интерпретации рекуррентных моделей глубокого обучения. Такие модели используются для обработки последовательностей данных \cite{lipton2015critical}. Однако для принятия решения при помощи такой модели необходимо доверять её предсказаниям. По этой причине требуется построить интерпретируемую модель, объясняющую предсказания исходной модели. Работа посвящена построению и выбору таких интерпретируемых моделей для некоторого класса рекуррентных сетей.

Рекуррентная нейронная сеть представляет из себя последовательность из слоёв нейронов: входного слоя, скрытых слоёв и выходного слоя \cite{sherstinsky2020fundrnn}. Отличительной особенностью от обыкновенных нейронных сетей являются циклические связи между нейронами. Такие связи позволяют запоминать состояния для обработки последовательностей данных.

Интерпретация должна быть \textbf{точной} и \textbf{согласованной} \cite{chu2019exact}. Интерпретация называется точной, если она согласуется с поведением модели. То есть показывает значимыми те признаки, которые значимо повлияли на предсказание модели. Интерпретация называется согласованной, если интерпретации близких объектов похожи. То есть значимости признаков отличаются незначительно.

Анализ зависимости предсказания модели от входных данных в реккурентных нейронных сетях является сложной задачей. Методы, рассмотренные в работах \cite{dosovitskiy2016inverting, zhou2018interpreting, NIPS2014_ea8fcd92, bastani2019interpreting, zhou2015learning, simonyan2014deep} являются либо неточными, то есть не отвечают реальному поведению модели, либо несогласованными, то есть совершенно разным образом объясняет предсказания на близких объектах.

В работах \cite{dosovitskiy2016inverting, zhou2018interpreting} рассмотрены методы, основанные на интерпретации признаков, выученных скрытыми слоями. Такой подход отражает поведение скрытых слоёв, но не показывает поведение сети в целом. В работах \cite{NIPS2014_ea8fcd92, bastani2019interpreting} предлагаются методы подражания модели. В этом подходе строится модель с похожим на исходную поведением. Построенная модель имеет более простую структуру, поэтому проще интерпретируется. Однако из-за недостаточно сложной структуры построенная модель недостаточно хорошо приближает исходную. Наконец, в работах \cite{zhou2015learning, simonyan2014deep} рассмотрены методы локальной интерпретации, в которых происходит анализ поведения модели в окрестности исходного объекта. В таком подходе получается точная интерпретация одного объекта, однако интерпретации близких объектов могут существенно отличаться. Таким образом, данный подход не предоставляет согласованные интерпретации.

Рассмотренный в данной работе подход является обобщением метода OpenBox для интерпретации нейронных сетей с кусочно-линейными  функциями активации \cite{chu2019exact}. Нейронная сеть представляется в виде эквивалентного набора линейных классификаторов. Каждый из них классифицирует объекты внутри некоторого выпуклого многогранника в пространстве признаков, поэтому интерпретации получаются согласованными.

На выборке IMDB Movie Review Dataset \cite{maas-EtAl:2011:ACL-HLT2011} проведён вычислительный эксперимент для анализа качества метода, а также для проверки интерпретаций на точность и согласованность. 

\section{Постановка задачи}
Рассмотрим рекуррентную нейронную сеть $\mathbf{f}$ с кусочно-линейными функциями активации. Входные данные обозначим через $\mathbf{x} \in \mathbf{X}$, где $\mathbf{X} \subset \mathbb{R}^d$ --- пространство признаков. Предсказание модели $\mathbf{f}$ обозначим через $\mathbf{y} \in \mathbf{Y}$, где $\mathbf{Y}$ --- пространство предсказаний.

Модель представляет из себя функцию классификации $\mathbf{f}: \mathbf{X} \to \mathbf{Y}$. Из-за сложной структуры сети трудно интерпретировать поведение функции $\mathbf{f}$, поэтому необходимо получить интерпретацию, которую способен понять человек.

Требуется построить модель, соответствующую функции $\mathbf{g}$, которая обладает следующими свойствами.

Во-первых модель должна быть интерпретируемой. То есть можно построить простую зависимость выходных данных от входных (интерпретацию). Также модель должна быть точной, то есть функции $\mathbf{f}$ и $\mathbf{g}$ должны совпадать на множестве $\mathbf{X}$. Помимо этого, модель должна быть согласованной, то есть интерпретации близких объектов в пространстве $\mathbf{X}$ должны быть похожи.

% Функция $F$ является кусочно-линейной, так как $\mathbf{N}~-$ рекуррентная нейронная сеть с кусочно-линейными функциями активации. Области, на которых функция $F$ линейна являются выпуклыми многогранниками.

% Предлагается рассмотреть модель $\mathbf{M}$, представляющую из себя множество линейных классификаторов $\left\{F_1, F_2, \dots, F_h, \dots\right\}$. Пространство признаков $\mathbf{X}$ разбивается на конечное множество выпуклых многогранников $\left\{P_1, P_2, \dots, P_h, \dots\right\}$. То есть $\bigsqcup\limits_{h} P_h=\mathbf{X}$. Классификатор $F_h$ определён на многограннике $P_h$. Модель $\mathbf{M}$ должна быть математически эквивалентна модели $\mathbf{N}$, то есть множество функций $\left\{F_1, F_2, \dots, F_h, \dots\right\}$ определённых на $\left\{P_1, P_2, \dots, P_h, \dots\right\}$ тождественно равно функции $F$, определённой на $\mathbf{X}$.

% Модель $\mathbf{M}$ обладает свойством точности, так как математически эквивалентна модели $\mathbf{N}$. То есть поведение двух моделей совпадает. $F|_{P_h} \equiv F_h$. Модель $\mathbf{M}$ также обладает свойством согласованности, так как близкие объекты попадают в один и тот же выпуклый многогранник $P_h$, а значит, классифицируются одним и тем же линейным классификатором $F_h$.

%Задача состоит в поиске такой модели $\mathbf{M}$, построении множества классификаторов по произвольной рекуррентной нейронной сети $\mathbf{N}$.

\section{Вычислительный эксперимент}

В рамках эксперимента рассматривается задача классификации отзывов на ресурсе IMDB. Используется выборка IMDB Movie Review Dataset \cite{maas-EtAl:2011:ACL-HLT2011} состоящяя из 50 000 отзывов, а также типов отзывов: положительный, отрицательный. Требуется по тексту отзыва определить вероятность принадлежности отзыва к классу положительных и отрицательных.

Для решения задачи используется рекуррентная нейронная сеть (обозначим через $\mathbf{f}$), принимающая векторы, полученные методом One-Hot Encoding \cite{onehot2018}. Рассматриваемая модель имеет 2 592 105 параметров. Безусловно, такую модель нельзя считать легко интерпретируемой.

Выборка разделена на две части: тренировочную и тестовую. Модель обучается на тренировочной выборке. После обучения измеряется качество модели на тестовой выборке. Была получена точность классификации (\textbf{accuracy}) около 60\%.

Интерпретацию модели $\mathbf{f}$ будем производить при помощи метода LIME \cite{ribeiro2016why}. Для построения интерпретации предсказания объекта $\mathbf{x}$ строится линейная модель $\mathbf{g}$ с небольшим числом параметров (число параметров обозначим через $K$), которая приближает поведение модели $\mathbf{f}$ в окрестности объекта $\mathbf{x}$. Для этого генерируются новые объекты $\mathbf{x_1}, \mathbf{x_2}, \dots, \mathbf{x_n}$ в окрестности объекта $\mathbf{x}$. Вычисляются предсказания $\mathbf{y_1}, \mathbf{y_2}, \dots, \mathbf{y_n}$ модели $\mathbf{f}$ на объектах $\mathbf{x_1}, \mathbf{x_2}, \dots, \mathbf{x_n}$. То есть $\mathbf{y_i}=\mathbf{f}(\mathbf{x_i})$.

Линейная модель $\mathbf{g}$ с $K$ параметрами строится таким образом, чтобы как можно точнее классифицировать объекты $\mathbf{x_1}, \mathbf{x_2}, \dots, \mathbf{x_n}$ с истинными метками $\mathbf{y_1}, \mathbf{y_2}, \dots, \mathbf{y_n}$. Интерпретацией в данном случае являются веса исходных признаков, а именно присутствия/отсутствия слов в отзыве.

\section{Результаты эксперимента}

Предсказание полученной методом LIME выглядит следующим образом.

\includegraphics[width=\textwidth]{figures/lime_exp.png}

Подсвеченные слова сильнее всего влияют на результат. Как можно заметить, модель отнесла отзыв к положительному классу, основываясь на наличии слов \texttt{and, able, men, last}. Понятно, что данные слова одинаково часто могут появиться как в положительном отзыве, так и в отрицательном. Таким образом, даже не учитывая метрику accuracy модели, можно сделать вывод, что модель непригодна для использования, так как делает предсказания на основе нерелевантных признаков. Однако из-за особенностей выборки непригодность модели можно не заметить, если рассматривать только метрики качества. 

\includegraphics[width=\textwidth]{figures/lime_exp2.png}

Вторая картинка показывает нам, что интерпретации несогласованны. А именно, значимые слова сильно отличаются. Такой эффект может быть связан с высокой сложностью модели.

Также можно отметить, что метод LIME является не самым эффективным методом с точки зрения времени.

\includegraphics[width=\textwidth]{../figures/lime_time}

Как видно из графика, на данной модели метод LIME способен обработать около 20 слов в секунду.

Вышеперечисленных недостатков мы постараемся избежать в новом подходе.

\bibliographystyle{unsrt}
\bibliography{Gaponov2022InterpretableRNN}

\end{document}
